{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 500) (5000,)\n",
      "(5000, 500)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from settings import DATA_DIR\n",
    "\n",
    "# Read the text file into a dataframe\n",
    "X = pd.read_csv(os.path.join(DATA_DIR, 'x_train.txt'), sep=' ', header=None).to_numpy()\n",
    "y = pd.read_csv(os.path.join(DATA_DIR, 'y_train.txt'), header=None).to_numpy().T[0]\n",
    "X_test = pd.read_csv(os.path.join(DATA_DIR, 'x_test.txt'), sep=' ', header=None).to_numpy()\n",
    "\n",
    "# Read the shape of the data\n",
    "print(X.shape, y.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cv_indices(n_observations, k_folds):\n",
    "    \"\"\"\n",
    "    Function creates cross-validation indices for k folds.\n",
    "\n",
    "    Arguments:\n",
    "        n_observations: Number of observations in whole dataset used in cross-validation\n",
    "        k_folds: number of folds for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "        splits: Training and testing indices\n",
    "    \"\"\"\n",
    "    indices = np.arange(n_observations)\n",
    "    np.random.shuffle(indices)\n",
    "    fold_sizes = np.full(k_folds, n_observations // k_folds, dtype=int)\n",
    "    fold_sizes[:n_observations % k_folds] += 1  # Distribute the remainder\n",
    "\n",
    "    current = 0\n",
    "    splits = []\n",
    "\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        val_indices = indices[start:stop]\n",
    "        train_indices = np.concatenate([indices[:start], indices[stop:]])\n",
    "        splits.append((train_indices, val_indices))\n",
    "        current = stop\n",
    "\n",
    "    return splits\n",
    "\n",
    "def calculate_score(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Function calculates custom score. It takes 1000 observations from test set with highest\n",
    "    probability of success and checks how many of them are truly 1. For each properly classified\n",
    "    observation it adds 10 to score. Then it dimishes score by 200 for each feature in train set.\n",
    "\n",
    "    Arguments:\n",
    "        model: model used for fit and predictions\n",
    "        X_train: numpy array containing training predictors\n",
    "        X_test: numpy array containing test predictors\n",
    "        y_train: numpy array containing training target variable\n",
    "        y_test: numpy array containing test target variable\n",
    "    \n",
    "    Returns:\n",
    "        score: custom score value for given data and model\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    proba_preds = model.predict_proba(X_test)\n",
    "    best_indices = np.argsort(proba_preds[:, 1])[-1000:]\n",
    "\n",
    "    properly_classfied_count = np.sum(y_test[best_indices])\n",
    "    n_feats = X_train.shape[1]\n",
    "\n",
    "    print(f\"Using {n_feats} features, we properly classified {properly_classfied_count} clients.\")\n",
    "\n",
    "    score = 10*properly_classfied_count - 200*n_feats\n",
    "    return score\n",
    "\n",
    "def cv(X, y, model, k_folds):\n",
    "    \"\"\"\n",
    "    Function performs cross validation with custom scoring function\n",
    "\n",
    "    Arguments:\n",
    "        X: numpy array with predictors\n",
    "        y: numpy array with target variable\n",
    "        model: model used in cross-validation\n",
    "        k_folds: number of folds for cross-validation\n",
    "\n",
    "    Returns:\n",
    "        scores: List of scores from custom metric for each cross-validation split\n",
    "    \"\"\"\n",
    "    fold_indices = prepare_cv_indices(\n",
    "        n_observations=X.shape[0],\n",
    "        k_folds=k_folds\n",
    "    )\n",
    "\n",
    "    scores = []\n",
    "    for train_indices, test_indices in fold_indices:\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        scores.append(calculate_score(model, X_train, X_test, y_train, y_test))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 500 features, we properly classified 600 clients.\n",
      "Using 500 features, we properly classified 587 clients.\n",
      "Using 500 features, we properly classified 616 clients.\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=5)\n",
    "k_folds = 3\n",
    "\n",
    "scores = cv(X, y, model, k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-94000, -94130, -93840]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectiveness evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effectiveness\n",
    "of your prediction will be assessed as follows:\n",
    "- For each designated customer who actually took advantage of the offer, the company will pay you $€10$.\n",
    "- For each variable used, you must pay $€200$ (the company bears the cost of obtaining information related\n",
    "to individual variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- deadline: 3rd June\n",
    "- at least 5 strategies (feature selection/model) must be implemented\n",
    "- CV necessary\n",
    "- feature selection methods\n",
    "- finding and finetuning standalone models\n",
    "- ensemble methods\n",
    "- self-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
